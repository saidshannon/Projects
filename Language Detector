import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from nltk.tokenize import RegexpTokenizer
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
import re


#Reading csv file
document=pd.read_csv('datasets/Language Detection.csv')
df=pd.read_csv('datasets/hindi.csv')
document1=document.append(df,ignore_index=True)
#print(document1)
#print(document1.info())
#print(document1.Language.value_counts())

#Plotting of the frequency of each class
counts=document1.groupby("Language").count()
plt.figure()
plt.style.use('ggplot')
ax=plt.axes
plt.barh(list(counts.index),counts.values.flatten())
for i,j in enumerate(counts.values.flatten()):
    plt.annotate(j,(j,i))
plt.yticks(fontsize=12)
plt.xlabel('Count')
plt.ylabel("Languages")
plt.title("Frequency of Each Class Language",fontsize=20)

#Removing numbers, brackets and alphabets from specific Languages
for i,j in zip(document1[document1['Language'].isin(['Russian','Malyalam','Hindi','Kannada','Tamil','Arabic'])].Text,document1[document1['Language'].isin(['Russian','Malyalam','Hindi','Kannada','Tamil','Arabic'])].Text.index):
    document1.Text.loc[j]=re.sub(pattern=r'[A-Za-z]',repl='',string=i)
for i,j in zip(document1['Text'],range(len(document1['Text']))):
    document1['Text'].loc[j]=re.sub(pattern=r'\d+|\[|\]|\(|\)|\{|\}|\@|\n',repl='',string=i)
print(document1)

#Regex tokenizer
token=RegexpTokenizer(r'\w+')

#Count Vectorizer
vector=CountVectorizer(ngram_range=(1,1),tokenizer=token.tokenize,stop_words='english')
token_count=vector.fit_transform(document1['Text'])
#print("Vector array using Countvectorizer:\n",token_count.toarray())
#print(vector.vocabulary_)

#TF-IDF Vectorizer
tvector=TfidfVectorizer(stop_words='english',ngram_range=(1,3),tokenizer=token.tokenize,analyzer='char')
token_count1=tvector.fit_transform(document1['Text'])
#print("Vector array of TDIFvectorizer:\n",token_count1.toarray())
#print(tvector.vocabulary_)

#Machine Learning
#Splitting training and testing dataset
X_train,X_test,y_train,y_test=train_test_split(token_count1,document1['Language'],test_size=0.3,random_state=42,stratify=document1['Language'])

#Naives Bayers Classifier algo
m=MultinomialNB().fit(X_train,y_train)
x=m.predict(X_test)
print("Naives Bayes accuracy: ",metrics.accuracy_score(y_test,x))

#Support Vector machine algo
svm=LinearSVC(max_iter=10000,C=1).fit(X_train,y_train)
y=svm.predict(X_test)
print("SVM classifier accuracy: ",metrics.accuracy_score(y_test,y))
print(metrics.confusion_matrix(y_test,y))
#Logistic Regressino
#log=LogisticRegression().fit(X_train,y_train)
#z=log.predict(X_test)
#print("Log accuracy: ",metrics.accuracy_score(y_test,z))

#Taking input text to get class(Language)
text="अक्टूबर"
print("The text typed is: ",text)
token_countinp=tvector.transform([text])
print("The language is: ",svm.predict(token_countinp)[0])

plt.show()










